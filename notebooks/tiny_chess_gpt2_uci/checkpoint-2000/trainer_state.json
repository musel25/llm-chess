{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.523809523809524,
  "eval_steps": 50,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.023809523809523808,
      "grad_norm": 2.5750672817230225,
      "learning_rate": 2.3999999999999997e-05,
      "loss": 7.36,
      "step": 5
    },
    {
      "epoch": 0.047619047619047616,
      "grad_norm": 1.9616755247116089,
      "learning_rate": 5.399999999999999e-05,
      "loss": 7.2545,
      "step": 10
    },
    {
      "epoch": 0.07142857142857142,
      "grad_norm": 1.6085728406906128,
      "learning_rate": 8.4e-05,
      "loss": 7.1342,
      "step": 15
    },
    {
      "epoch": 0.09523809523809523,
      "grad_norm": 1.379592776298523,
      "learning_rate": 0.00011399999999999999,
      "loss": 6.9991,
      "step": 20
    },
    {
      "epoch": 0.11904761904761904,
      "grad_norm": 1.2382476329803467,
      "learning_rate": 0.00014399999999999998,
      "loss": 6.885,
      "step": 25
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 1.2407149076461792,
      "learning_rate": 0.00017399999999999997,
      "loss": 6.7588,
      "step": 30
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 1.1570842266082764,
      "learning_rate": 0.000204,
      "loss": 6.6175,
      "step": 35
    },
    {
      "epoch": 0.19047619047619047,
      "grad_norm": 0.9697062969207764,
      "learning_rate": 0.000234,
      "loss": 6.495,
      "step": 40
    },
    {
      "epoch": 0.21428571428571427,
      "grad_norm": 1.0138278007507324,
      "learning_rate": 0.00026399999999999997,
      "loss": 6.3723,
      "step": 45
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 1.3530882596969604,
      "learning_rate": 0.000294,
      "loss": 6.2752,
      "step": 50
    },
    {
      "epoch": 0.23809523809523808,
      "eval_loss": 5.833829879760742,
      "eval_runtime": 0.9695,
      "eval_samples_per_second": 602.357,
      "eval_steps_per_second": 19.597,
      "step": 50
    },
    {
      "epoch": 0.2619047619047619,
      "grad_norm": 1.2054648399353027,
      "learning_rate": 0.00029938461538461537,
      "loss": 6.088,
      "step": 55
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 1.0128041505813599,
      "learning_rate": 0.0002986153846153846,
      "loss": 5.8716,
      "step": 60
    },
    {
      "epoch": 0.30952380952380953,
      "grad_norm": 0.9498693943023682,
      "learning_rate": 0.00029784615384615386,
      "loss": 5.7959,
      "step": 65
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 1.1216925382614136,
      "learning_rate": 0.000297076923076923,
      "loss": 5.5776,
      "step": 70
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 1.1416178941726685,
      "learning_rate": 0.0002963076923076923,
      "loss": 5.5483,
      "step": 75
    },
    {
      "epoch": 0.38095238095238093,
      "grad_norm": 1.0371925830841064,
      "learning_rate": 0.0002955384615384615,
      "loss": 5.3978,
      "step": 80
    },
    {
      "epoch": 0.40476190476190477,
      "grad_norm": 1.0820914506912231,
      "learning_rate": 0.0002947692307692307,
      "loss": 5.2642,
      "step": 85
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 1.0322529077529907,
      "learning_rate": 0.000294,
      "loss": 5.2301,
      "step": 90
    },
    {
      "epoch": 0.4523809523809524,
      "grad_norm": 0.9583760499954224,
      "learning_rate": 0.0002932307692307692,
      "loss": 5.2216,
      "step": 95
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 0.9875195622444153,
      "learning_rate": 0.0002924615384615384,
      "loss": 5.1979,
      "step": 100
    },
    {
      "epoch": 0.47619047619047616,
      "eval_loss": 4.474184513092041,
      "eval_runtime": 1.7246,
      "eval_samples_per_second": 338.634,
      "eval_steps_per_second": 11.017,
      "step": 100
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9693410992622375,
      "learning_rate": 0.0002916923076923077,
      "loss": 4.8678,
      "step": 105
    },
    {
      "epoch": 0.5238095238095238,
      "grad_norm": 1.0467835664749146,
      "learning_rate": 0.0002909230769230769,
      "loss": 4.9789,
      "step": 110
    },
    {
      "epoch": 0.5476190476190477,
      "grad_norm": 0.9932897090911865,
      "learning_rate": 0.0002901538461538461,
      "loss": 4.9368,
      "step": 115
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 1.0679181814193726,
      "learning_rate": 0.0002893846153846154,
      "loss": 4.7457,
      "step": 120
    },
    {
      "epoch": 0.5952380952380952,
      "grad_norm": 1.1605526208877563,
      "learning_rate": 0.0002886153846153846,
      "loss": 4.7201,
      "step": 125
    },
    {
      "epoch": 0.6190476190476191,
      "grad_norm": 1.159515619277954,
      "learning_rate": 0.00028784615384615383,
      "loss": 4.8045,
      "step": 130
    },
    {
      "epoch": 0.6428571428571429,
      "grad_norm": 1.3961772918701172,
      "learning_rate": 0.00028707692307692305,
      "loss": 4.727,
      "step": 135
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.9550957679748535,
      "learning_rate": 0.00028630769230769226,
      "loss": 4.7509,
      "step": 140
    },
    {
      "epoch": 0.6904761904761905,
      "grad_norm": 0.9761274456977844,
      "learning_rate": 0.00028553846153846153,
      "loss": 4.3938,
      "step": 145
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.8014171123504639,
      "learning_rate": 0.00028476923076923075,
      "loss": 4.4369,
      "step": 150
    },
    {
      "epoch": 0.7142857142857143,
      "eval_loss": 3.7954185009002686,
      "eval_runtime": 1.0672,
      "eval_samples_per_second": 547.214,
      "eval_steps_per_second": 17.803,
      "step": 150
    },
    {
      "epoch": 0.7380952380952381,
      "grad_norm": 0.9739973545074463,
      "learning_rate": 0.00028399999999999996,
      "loss": 4.3978,
      "step": 155
    },
    {
      "epoch": 0.7619047619047619,
      "grad_norm": 0.8323874473571777,
      "learning_rate": 0.0002832307692307692,
      "loss": 4.4586,
      "step": 160
    },
    {
      "epoch": 0.7857142857142857,
      "grad_norm": 0.8830251693725586,
      "learning_rate": 0.00028246153846153845,
      "loss": 4.3891,
      "step": 165
    },
    {
      "epoch": 0.8095238095238095,
      "grad_norm": 0.8516327142715454,
      "learning_rate": 0.00028169230769230767,
      "loss": 4.5029,
      "step": 170
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 1.0648138523101807,
      "learning_rate": 0.0002809230769230769,
      "loss": 4.3021,
      "step": 175
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.9741135239601135,
      "learning_rate": 0.00028015384615384615,
      "loss": 4.5274,
      "step": 180
    },
    {
      "epoch": 0.8809523809523809,
      "grad_norm": 0.8384609222412109,
      "learning_rate": 0.00027938461538461537,
      "loss": 4.1408,
      "step": 185
    },
    {
      "epoch": 0.9047619047619048,
      "grad_norm": 0.836184024810791,
      "learning_rate": 0.0002786153846153846,
      "loss": 4.1796,
      "step": 190
    },
    {
      "epoch": 0.9285714285714286,
      "grad_norm": 0.8208447694778442,
      "learning_rate": 0.0002778461538461538,
      "loss": 4.3479,
      "step": 195
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 0.8758925795555115,
      "learning_rate": 0.000277076923076923,
      "loss": 4.261,
      "step": 200
    },
    {
      "epoch": 0.9523809523809523,
      "eval_loss": 3.4782209396362305,
      "eval_runtime": 0.9624,
      "eval_samples_per_second": 606.806,
      "eval_steps_per_second": 19.742,
      "step": 200
    },
    {
      "epoch": 0.9761904761904762,
      "grad_norm": 0.8636459112167358,
      "learning_rate": 0.0002763076923076923,
      "loss": 4.4986,
      "step": 205
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.2833516597747803,
      "learning_rate": 0.0002755384615384615,
      "loss": 4.2756,
      "step": 210
    },
    {
      "epoch": 1.0238095238095237,
      "grad_norm": 1.034921407699585,
      "learning_rate": 0.0002747692307692307,
      "loss": 4.0614,
      "step": 215
    },
    {
      "epoch": 1.0476190476190477,
      "grad_norm": 0.9133208990097046,
      "learning_rate": 0.000274,
      "loss": 4.0815,
      "step": 220
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 0.8474701642990112,
      "learning_rate": 0.0002732307692307692,
      "loss": 3.999,
      "step": 225
    },
    {
      "epoch": 1.0952380952380953,
      "grad_norm": 0.8156023025512695,
      "learning_rate": 0.0002724615384615384,
      "loss": 4.0901,
      "step": 230
    },
    {
      "epoch": 1.119047619047619,
      "grad_norm": 1.2521328926086426,
      "learning_rate": 0.0002716923076923077,
      "loss": 4.2072,
      "step": 235
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.766877293586731,
      "learning_rate": 0.0002709230769230769,
      "loss": 4.3119,
      "step": 240
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 0.9214289784431458,
      "learning_rate": 0.00027015384615384613,
      "loss": 3.8623,
      "step": 245
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.8640584349632263,
      "learning_rate": 0.0002693846153846154,
      "loss": 3.9596,
      "step": 250
    },
    {
      "epoch": 1.1904761904761905,
      "eval_loss": 3.3107244968414307,
      "eval_runtime": 0.3192,
      "eval_samples_per_second": 1829.792,
      "eval_steps_per_second": 59.531,
      "step": 250
    },
    {
      "epoch": 1.2142857142857142,
      "grad_norm": 1.0530285835266113,
      "learning_rate": 0.00026861538461538456,
      "loss": 3.9976,
      "step": 255
    },
    {
      "epoch": 1.2380952380952381,
      "grad_norm": 1.0291008949279785,
      "learning_rate": 0.00026784615384615383,
      "loss": 4.3029,
      "step": 260
    },
    {
      "epoch": 1.2619047619047619,
      "grad_norm": 0.8631266355514526,
      "learning_rate": 0.00026707692307692305,
      "loss": 4.1172,
      "step": 265
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 0.9413098096847534,
      "learning_rate": 0.00026630769230769226,
      "loss": 4.0296,
      "step": 270
    },
    {
      "epoch": 1.3095238095238095,
      "grad_norm": 1.3244506120681763,
      "learning_rate": 0.00026553846153846153,
      "loss": 4.0784,
      "step": 275
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.9477655291557312,
      "learning_rate": 0.00026476923076923075,
      "loss": 3.9092,
      "step": 280
    },
    {
      "epoch": 1.3571428571428572,
      "grad_norm": 0.8531676530838013,
      "learning_rate": 0.00026399999999999997,
      "loss": 4.3358,
      "step": 285
    },
    {
      "epoch": 1.380952380952381,
      "grad_norm": 0.9627373814582825,
      "learning_rate": 0.00026323076923076924,
      "loss": 3.8692,
      "step": 290
    },
    {
      "epoch": 1.4047619047619047,
      "grad_norm": 1.0405054092407227,
      "learning_rate": 0.00026246153846153845,
      "loss": 4.1826,
      "step": 295
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.9554397463798523,
      "learning_rate": 0.00026169230769230767,
      "loss": 3.8304,
      "step": 300
    },
    {
      "epoch": 1.4285714285714286,
      "eval_loss": 3.178797960281372,
      "eval_runtime": 0.3643,
      "eval_samples_per_second": 1603.029,
      "eval_steps_per_second": 52.153,
      "step": 300
    },
    {
      "epoch": 1.4523809523809523,
      "grad_norm": 0.8406051993370056,
      "learning_rate": 0.00026092307692307694,
      "loss": 3.8719,
      "step": 305
    },
    {
      "epoch": 1.4761904761904763,
      "grad_norm": 1.0991270542144775,
      "learning_rate": 0.00026015384615384616,
      "loss": 3.8702,
      "step": 310
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.9697576761245728,
      "learning_rate": 0.00025938461538461537,
      "loss": 4.0948,
      "step": 315
    },
    {
      "epoch": 1.5238095238095237,
      "grad_norm": 1.0577698945999146,
      "learning_rate": 0.0002586153846153846,
      "loss": 3.9928,
      "step": 320
    },
    {
      "epoch": 1.5476190476190477,
      "grad_norm": 1.174237847328186,
      "learning_rate": 0.0002578461538461538,
      "loss": 3.8902,
      "step": 325
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 1.1182535886764526,
      "learning_rate": 0.000257076923076923,
      "loss": 3.7224,
      "step": 330
    },
    {
      "epoch": 1.5952380952380953,
      "grad_norm": 0.903889000415802,
      "learning_rate": 0.0002563076923076923,
      "loss": 3.9513,
      "step": 335
    },
    {
      "epoch": 1.619047619047619,
      "grad_norm": 1.016171932220459,
      "learning_rate": 0.0002555384615384615,
      "loss": 3.9617,
      "step": 340
    },
    {
      "epoch": 1.6428571428571428,
      "grad_norm": 0.974933922290802,
      "learning_rate": 0.0002547692307692307,
      "loss": 3.8707,
      "step": 345
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.9505508542060852,
      "learning_rate": 0.000254,
      "loss": 4.0369,
      "step": 350
    },
    {
      "epoch": 1.6666666666666665,
      "eval_loss": 3.0910732746124268,
      "eval_runtime": 1.2122,
      "eval_samples_per_second": 481.774,
      "eval_steps_per_second": 15.674,
      "step": 350
    },
    {
      "epoch": 1.6904761904761905,
      "grad_norm": 1.0005292892456055,
      "learning_rate": 0.0002532307692307692,
      "loss": 3.7542,
      "step": 355
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 1.045179843902588,
      "learning_rate": 0.0002524615384615384,
      "loss": 3.9234,
      "step": 360
    },
    {
      "epoch": 1.7380952380952381,
      "grad_norm": 1.0885121822357178,
      "learning_rate": 0.0002516923076923077,
      "loss": 3.9109,
      "step": 365
    },
    {
      "epoch": 1.7619047619047619,
      "grad_norm": 1.0146857500076294,
      "learning_rate": 0.0002509230769230769,
      "loss": 3.8244,
      "step": 370
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 1.0253241062164307,
      "learning_rate": 0.00025015384615384613,
      "loss": 3.8858,
      "step": 375
    },
    {
      "epoch": 1.8095238095238095,
      "grad_norm": 1.0986738204956055,
      "learning_rate": 0.00024938461538461535,
      "loss": 3.7902,
      "step": 380
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 1.00807785987854,
      "learning_rate": 0.00024861538461538456,
      "loss": 4.028,
      "step": 385
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 1.0533148050308228,
      "learning_rate": 0.00024784615384615383,
      "loss": 3.8693,
      "step": 390
    },
    {
      "epoch": 1.880952380952381,
      "grad_norm": 1.0085185766220093,
      "learning_rate": 0.00024707692307692305,
      "loss": 3.6561,
      "step": 395
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 1.1247042417526245,
      "learning_rate": 0.00024630769230769226,
      "loss": 3.8393,
      "step": 400
    },
    {
      "epoch": 1.9047619047619047,
      "eval_loss": 3.021315813064575,
      "eval_runtime": 1.3963,
      "eval_samples_per_second": 418.253,
      "eval_steps_per_second": 13.608,
      "step": 400
    },
    {
      "epoch": 1.9285714285714286,
      "grad_norm": 1.097296953201294,
      "learning_rate": 0.00024553846153846154,
      "loss": 3.6099,
      "step": 405
    },
    {
      "epoch": 1.9523809523809523,
      "grad_norm": 1.0297281742095947,
      "learning_rate": 0.00024476923076923075,
      "loss": 3.7546,
      "step": 410
    },
    {
      "epoch": 1.9761904761904763,
      "grad_norm": 0.9857218861579895,
      "learning_rate": 0.000244,
      "loss": 3.6538,
      "step": 415
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.5660277605056763,
      "learning_rate": 0.0002432307692307692,
      "loss": 3.6273,
      "step": 420
    },
    {
      "epoch": 2.0238095238095237,
      "grad_norm": 1.064869999885559,
      "learning_rate": 0.00024246153846153845,
      "loss": 3.8384,
      "step": 425
    },
    {
      "epoch": 2.0476190476190474,
      "grad_norm": 1.1338194608688354,
      "learning_rate": 0.0002416923076923077,
      "loss": 3.7328,
      "step": 430
    },
    {
      "epoch": 2.0714285714285716,
      "grad_norm": 1.2759878635406494,
      "learning_rate": 0.0002409230769230769,
      "loss": 3.5447,
      "step": 435
    },
    {
      "epoch": 2.0952380952380953,
      "grad_norm": 1.0110255479812622,
      "learning_rate": 0.00024015384615384613,
      "loss": 3.7955,
      "step": 440
    },
    {
      "epoch": 2.119047619047619,
      "grad_norm": 1.0869983434677124,
      "learning_rate": 0.00023938461538461535,
      "loss": 3.5917,
      "step": 445
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 1.065477967262268,
      "learning_rate": 0.0002386153846153846,
      "loss": 3.704,
      "step": 450
    },
    {
      "epoch": 2.142857142857143,
      "eval_loss": 2.957608461380005,
      "eval_runtime": 0.622,
      "eval_samples_per_second": 938.975,
      "eval_steps_per_second": 30.549,
      "step": 450
    },
    {
      "epoch": 2.1666666666666665,
      "grad_norm": 1.0482089519500732,
      "learning_rate": 0.0002378461538461538,
      "loss": 3.5123,
      "step": 455
    },
    {
      "epoch": 2.1904761904761907,
      "grad_norm": 1.102527379989624,
      "learning_rate": 0.00023707692307692305,
      "loss": 3.6901,
      "step": 460
    },
    {
      "epoch": 2.2142857142857144,
      "grad_norm": 1.0326131582260132,
      "learning_rate": 0.0002363076923076923,
      "loss": 3.6287,
      "step": 465
    },
    {
      "epoch": 2.238095238095238,
      "grad_norm": 1.1820260286331177,
      "learning_rate": 0.0002355384615384615,
      "loss": 3.7413,
      "step": 470
    },
    {
      "epoch": 2.261904761904762,
      "grad_norm": 1.1639922857284546,
      "learning_rate": 0.00023476923076923075,
      "loss": 3.8235,
      "step": 475
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 1.0562920570373535,
      "learning_rate": 0.000234,
      "loss": 3.8549,
      "step": 480
    },
    {
      "epoch": 2.3095238095238093,
      "grad_norm": 1.0478817224502563,
      "learning_rate": 0.0002332307692307692,
      "loss": 3.5878,
      "step": 485
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 1.0451281070709229,
      "learning_rate": 0.00023246153846153846,
      "loss": 3.6321,
      "step": 490
    },
    {
      "epoch": 2.357142857142857,
      "grad_norm": 1.066043734550476,
      "learning_rate": 0.0002316923076923077,
      "loss": 3.7404,
      "step": 495
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 1.109315276145935,
      "learning_rate": 0.0002309230769230769,
      "loss": 3.8472,
      "step": 500
    },
    {
      "epoch": 2.380952380952381,
      "eval_loss": 2.906095266342163,
      "eval_runtime": 1.1172,
      "eval_samples_per_second": 522.726,
      "eval_steps_per_second": 17.006,
      "step": 500
    },
    {
      "epoch": 2.4047619047619047,
      "grad_norm": 1.3366408348083496,
      "learning_rate": 0.00023015384615384613,
      "loss": 3.5285,
      "step": 505
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 1.0152652263641357,
      "learning_rate": 0.00022938461538461535,
      "loss": 3.7433,
      "step": 510
    },
    {
      "epoch": 2.4523809523809526,
      "grad_norm": 0.9699850082397461,
      "learning_rate": 0.0002286153846153846,
      "loss": 3.7742,
      "step": 515
    },
    {
      "epoch": 2.4761904761904763,
      "grad_norm": 1.0194745063781738,
      "learning_rate": 0.00022784615384615383,
      "loss": 3.5657,
      "step": 520
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.1254792213439941,
      "learning_rate": 0.00022707692307692305,
      "loss": 3.7866,
      "step": 525
    },
    {
      "epoch": 2.5238095238095237,
      "grad_norm": 1.08682382106781,
      "learning_rate": 0.0002263076923076923,
      "loss": 3.7788,
      "step": 530
    },
    {
      "epoch": 2.5476190476190474,
      "grad_norm": 0.9757729172706604,
      "learning_rate": 0.0002255384615384615,
      "loss": 3.8998,
      "step": 535
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 1.0411099195480347,
      "learning_rate": 0.00022476923076923075,
      "loss": 3.7194,
      "step": 540
    },
    {
      "epoch": 2.5952380952380953,
      "grad_norm": 1.1127214431762695,
      "learning_rate": 0.000224,
      "loss": 3.6308,
      "step": 545
    },
    {
      "epoch": 2.619047619047619,
      "grad_norm": 1.125675082206726,
      "learning_rate": 0.0002232307692307692,
      "loss": 3.5133,
      "step": 550
    },
    {
      "epoch": 2.619047619047619,
      "eval_loss": 2.8525795936584473,
      "eval_runtime": 1.7851,
      "eval_samples_per_second": 327.147,
      "eval_steps_per_second": 10.643,
      "step": 550
    },
    {
      "epoch": 2.642857142857143,
      "grad_norm": 1.0554497241973877,
      "learning_rate": 0.00022246153846153846,
      "loss": 3.6462,
      "step": 555
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 1.0382572412490845,
      "learning_rate": 0.00022169230769230765,
      "loss": 3.737,
      "step": 560
    },
    {
      "epoch": 2.6904761904761907,
      "grad_norm": 1.1730175018310547,
      "learning_rate": 0.0002209230769230769,
      "loss": 3.8326,
      "step": 565
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 1.0062403678894043,
      "learning_rate": 0.00022015384615384613,
      "loss": 3.7321,
      "step": 570
    },
    {
      "epoch": 2.738095238095238,
      "grad_norm": 1.1666227579116821,
      "learning_rate": 0.00021938461538461535,
      "loss": 3.5621,
      "step": 575
    },
    {
      "epoch": 2.761904761904762,
      "grad_norm": 1.2805322408676147,
      "learning_rate": 0.0002186153846153846,
      "loss": 3.7092,
      "step": 580
    },
    {
      "epoch": 2.7857142857142856,
      "grad_norm": 1.1801711320877075,
      "learning_rate": 0.00021784615384615383,
      "loss": 3.6779,
      "step": 585
    },
    {
      "epoch": 2.8095238095238093,
      "grad_norm": 1.0810906887054443,
      "learning_rate": 0.00021707692307692305,
      "loss": 3.7688,
      "step": 590
    },
    {
      "epoch": 2.8333333333333335,
      "grad_norm": 1.0916398763656616,
      "learning_rate": 0.0002163076923076923,
      "loss": 3.5691,
      "step": 595
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 1.1577589511871338,
      "learning_rate": 0.00021553846153846154,
      "loss": 3.716,
      "step": 600
    },
    {
      "epoch": 2.857142857142857,
      "eval_loss": 2.821957588195801,
      "eval_runtime": 0.8097,
      "eval_samples_per_second": 721.24,
      "eval_steps_per_second": 23.465,
      "step": 600
    },
    {
      "epoch": 2.880952380952381,
      "grad_norm": 1.003844141960144,
      "learning_rate": 0.00021476923076923075,
      "loss": 3.7161,
      "step": 605
    },
    {
      "epoch": 2.9047619047619047,
      "grad_norm": 1.0710526704788208,
      "learning_rate": 0.000214,
      "loss": 3.7863,
      "step": 610
    },
    {
      "epoch": 2.928571428571429,
      "grad_norm": 1.036994218826294,
      "learning_rate": 0.00021323076923076921,
      "loss": 3.5034,
      "step": 615
    },
    {
      "epoch": 2.9523809523809526,
      "grad_norm": 1.1573330163955688,
      "learning_rate": 0.00021246153846153843,
      "loss": 3.6531,
      "step": 620
    },
    {
      "epoch": 2.9761904761904763,
      "grad_norm": 1.1295585632324219,
      "learning_rate": 0.00021169230769230767,
      "loss": 3.7437,
      "step": 625
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.7073659896850586,
      "learning_rate": 0.0002109230769230769,
      "loss": 3.4369,
      "step": 630
    },
    {
      "epoch": 3.0238095238095237,
      "grad_norm": 1.1923738718032837,
      "learning_rate": 0.00021015384615384613,
      "loss": 3.2322,
      "step": 635
    },
    {
      "epoch": 3.0476190476190474,
      "grad_norm": 1.1998999118804932,
      "learning_rate": 0.00020938461538461535,
      "loss": 3.6896,
      "step": 640
    },
    {
      "epoch": 3.0714285714285716,
      "grad_norm": 1.099290132522583,
      "learning_rate": 0.0002086153846153846,
      "loss": 3.5303,
      "step": 645
    },
    {
      "epoch": 3.0952380952380953,
      "grad_norm": 1.3696080446243286,
      "learning_rate": 0.00020784615384615384,
      "loss": 3.7217,
      "step": 650
    },
    {
      "epoch": 3.0952380952380953,
      "eval_loss": 2.7781269550323486,
      "eval_runtime": 1.414,
      "eval_samples_per_second": 412.999,
      "eval_steps_per_second": 13.437,
      "step": 650
    },
    {
      "epoch": 3.119047619047619,
      "grad_norm": 1.170891523361206,
      "learning_rate": 0.00020707692307692305,
      "loss": 3.4923,
      "step": 655
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 1.103559970855713,
      "learning_rate": 0.0002063076923076923,
      "loss": 3.5896,
      "step": 660
    },
    {
      "epoch": 3.1666666666666665,
      "grad_norm": 1.21775484085083,
      "learning_rate": 0.00020553846153846154,
      "loss": 3.7792,
      "step": 665
    },
    {
      "epoch": 3.1904761904761907,
      "grad_norm": 1.1143548488616943,
      "learning_rate": 0.00020476923076923076,
      "loss": 3.5699,
      "step": 670
    },
    {
      "epoch": 3.2142857142857144,
      "grad_norm": 1.1221650838851929,
      "learning_rate": 0.000204,
      "loss": 3.6299,
      "step": 675
    },
    {
      "epoch": 3.238095238095238,
      "grad_norm": 1.1828457117080688,
      "learning_rate": 0.0002032307692307692,
      "loss": 3.8199,
      "step": 680
    },
    {
      "epoch": 3.261904761904762,
      "grad_norm": 1.225864291191101,
      "learning_rate": 0.00020246153846153843,
      "loss": 3.4746,
      "step": 685
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 1.1547796726226807,
      "learning_rate": 0.00020169230769230767,
      "loss": 3.4934,
      "step": 690
    },
    {
      "epoch": 3.3095238095238093,
      "grad_norm": 1.3966959714889526,
      "learning_rate": 0.0002009230769230769,
      "loss": 3.6077,
      "step": 695
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 1.2540630102157593,
      "learning_rate": 0.00020015384615384613,
      "loss": 3.5326,
      "step": 700
    },
    {
      "epoch": 3.3333333333333335,
      "eval_loss": 2.751368999481201,
      "eval_runtime": 0.7242,
      "eval_samples_per_second": 806.371,
      "eval_steps_per_second": 26.235,
      "step": 700
    },
    {
      "epoch": 3.357142857142857,
      "grad_norm": 1.2626615762710571,
      "learning_rate": 0.00019938461538461538,
      "loss": 3.7127,
      "step": 705
    },
    {
      "epoch": 3.380952380952381,
      "grad_norm": 1.1843293905258179,
      "learning_rate": 0.0001986153846153846,
      "loss": 3.7158,
      "step": 710
    },
    {
      "epoch": 3.4047619047619047,
      "grad_norm": 1.138295292854309,
      "learning_rate": 0.00019784615384615384,
      "loss": 3.5128,
      "step": 715
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 1.2511868476867676,
      "learning_rate": 0.00019707692307692305,
      "loss": 3.6698,
      "step": 720
    },
    {
      "epoch": 3.4523809523809526,
      "grad_norm": 1.160968542098999,
      "learning_rate": 0.0001963076923076923,
      "loss": 3.3566,
      "step": 725
    },
    {
      "epoch": 3.4761904761904763,
      "grad_norm": 1.209427833557129,
      "learning_rate": 0.00019553846153846154,
      "loss": 3.6485,
      "step": 730
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.2654783725738525,
      "learning_rate": 0.00019476923076923076,
      "loss": 3.6128,
      "step": 735
    },
    {
      "epoch": 3.5238095238095237,
      "grad_norm": 1.2617822885513306,
      "learning_rate": 0.00019399999999999997,
      "loss": 3.4615,
      "step": 740
    },
    {
      "epoch": 3.5476190476190474,
      "grad_norm": 1.3262648582458496,
      "learning_rate": 0.0001932307692307692,
      "loss": 3.4119,
      "step": 745
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 1.1398415565490723,
      "learning_rate": 0.00019246153846153843,
      "loss": 3.5384,
      "step": 750
    },
    {
      "epoch": 3.571428571428571,
      "eval_loss": 2.72745418548584,
      "eval_runtime": 0.5944,
      "eval_samples_per_second": 982.575,
      "eval_steps_per_second": 31.967,
      "step": 750
    },
    {
      "epoch": 3.5952380952380953,
      "grad_norm": 1.2180157899856567,
      "learning_rate": 0.00019169230769230768,
      "loss": 3.3901,
      "step": 755
    },
    {
      "epoch": 3.619047619047619,
      "grad_norm": 1.1631802320480347,
      "learning_rate": 0.0001909230769230769,
      "loss": 3.6899,
      "step": 760
    },
    {
      "epoch": 3.642857142857143,
      "grad_norm": 1.2748620510101318,
      "learning_rate": 0.00019015384615384613,
      "loss": 3.6619,
      "step": 765
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 1.1199805736541748,
      "learning_rate": 0.00018938461538461538,
      "loss": 3.5104,
      "step": 770
    },
    {
      "epoch": 3.6904761904761907,
      "grad_norm": 1.2091388702392578,
      "learning_rate": 0.0001886153846153846,
      "loss": 3.3121,
      "step": 775
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 1.2250657081604004,
      "learning_rate": 0.00018784615384615384,
      "loss": 3.4073,
      "step": 780
    },
    {
      "epoch": 3.738095238095238,
      "grad_norm": 1.2169593572616577,
      "learning_rate": 0.00018707692307692308,
      "loss": 3.8474,
      "step": 785
    },
    {
      "epoch": 3.761904761904762,
      "grad_norm": 1.269931674003601,
      "learning_rate": 0.0001863076923076923,
      "loss": 3.1994,
      "step": 790
    },
    {
      "epoch": 3.7857142857142856,
      "grad_norm": 1.149106502532959,
      "learning_rate": 0.00018553846153846154,
      "loss": 3.2396,
      "step": 795
    },
    {
      "epoch": 3.8095238095238093,
      "grad_norm": 1.2055752277374268,
      "learning_rate": 0.00018476923076923076,
      "loss": 3.5717,
      "step": 800
    },
    {
      "epoch": 3.8095238095238093,
      "eval_loss": 2.6953318119049072,
      "eval_runtime": 0.7011,
      "eval_samples_per_second": 832.952,
      "eval_steps_per_second": 27.099,
      "step": 800
    },
    {
      "epoch": 3.8333333333333335,
      "grad_norm": 1.204681158065796,
      "learning_rate": 0.00018399999999999997,
      "loss": 3.7467,
      "step": 805
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 1.288804054260254,
      "learning_rate": 0.00018323076923076922,
      "loss": 3.7737,
      "step": 810
    },
    {
      "epoch": 3.880952380952381,
      "grad_norm": 1.1312627792358398,
      "learning_rate": 0.00018246153846153843,
      "loss": 3.6306,
      "step": 815
    },
    {
      "epoch": 3.9047619047619047,
      "grad_norm": 1.2220853567123413,
      "learning_rate": 0.00018169230769230768,
      "loss": 3.5472,
      "step": 820
    },
    {
      "epoch": 3.928571428571429,
      "grad_norm": 1.1892707347869873,
      "learning_rate": 0.0001809230769230769,
      "loss": 3.5403,
      "step": 825
    },
    {
      "epoch": 3.9523809523809526,
      "grad_norm": 1.2023839950561523,
      "learning_rate": 0.00018015384615384614,
      "loss": 3.2969,
      "step": 830
    },
    {
      "epoch": 3.9761904761904763,
      "grad_norm": 1.2234524488449097,
      "learning_rate": 0.00017938461538461538,
      "loss": 3.4233,
      "step": 835
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.028562068939209,
      "learning_rate": 0.0001786153846153846,
      "loss": 3.5808,
      "step": 840
    },
    {
      "epoch": 4.023809523809524,
      "grad_norm": 1.2089405059814453,
      "learning_rate": 0.00017784615384615384,
      "loss": 3.1711,
      "step": 845
    },
    {
      "epoch": 4.0476190476190474,
      "grad_norm": 1.4250271320343018,
      "learning_rate": 0.00017707692307692308,
      "loss": 3.402,
      "step": 850
    },
    {
      "epoch": 4.0476190476190474,
      "eval_loss": 2.674802780151367,
      "eval_runtime": 0.5915,
      "eval_samples_per_second": 987.398,
      "eval_steps_per_second": 32.124,
      "step": 850
    },
    {
      "epoch": 4.071428571428571,
      "grad_norm": 1.204744577407837,
      "learning_rate": 0.0001763076923076923,
      "loss": 3.7167,
      "step": 855
    },
    {
      "epoch": 4.095238095238095,
      "grad_norm": 1.2489509582519531,
      "learning_rate": 0.00017553846153846154,
      "loss": 3.2875,
      "step": 860
    },
    {
      "epoch": 4.119047619047619,
      "grad_norm": 1.3126027584075928,
      "learning_rate": 0.00017476923076923073,
      "loss": 3.2949,
      "step": 865
    },
    {
      "epoch": 4.142857142857143,
      "grad_norm": 1.2271453142166138,
      "learning_rate": 0.00017399999999999997,
      "loss": 3.4226,
      "step": 870
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 1.234576940536499,
      "learning_rate": 0.00017323076923076922,
      "loss": 3.219,
      "step": 875
    },
    {
      "epoch": 4.190476190476191,
      "grad_norm": 1.2809460163116455,
      "learning_rate": 0.00017246153846153843,
      "loss": 3.5701,
      "step": 880
    },
    {
      "epoch": 4.214285714285714,
      "grad_norm": 1.1769404411315918,
      "learning_rate": 0.00017169230769230768,
      "loss": 3.3146,
      "step": 885
    },
    {
      "epoch": 4.238095238095238,
      "grad_norm": 1.364782691001892,
      "learning_rate": 0.00017092307692307692,
      "loss": 3.47,
      "step": 890
    },
    {
      "epoch": 4.261904761904762,
      "grad_norm": 1.160744309425354,
      "learning_rate": 0.00017015384615384614,
      "loss": 3.3763,
      "step": 895
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 1.144422173500061,
      "learning_rate": 0.00016938461538461538,
      "loss": 3.5384,
      "step": 900
    },
    {
      "epoch": 4.285714285714286,
      "eval_loss": 2.6539928913116455,
      "eval_runtime": 0.6996,
      "eval_samples_per_second": 834.737,
      "eval_steps_per_second": 27.158,
      "step": 900
    },
    {
      "epoch": 4.309523809523809,
      "grad_norm": 1.3247896432876587,
      "learning_rate": 0.0001686153846153846,
      "loss": 3.3399,
      "step": 905
    },
    {
      "epoch": 4.333333333333333,
      "grad_norm": 1.2063809633255005,
      "learning_rate": 0.00016784615384615384,
      "loss": 3.6079,
      "step": 910
    },
    {
      "epoch": 4.357142857142857,
      "grad_norm": 1.2010095119476318,
      "learning_rate": 0.00016707692307692308,
      "loss": 3.3382,
      "step": 915
    },
    {
      "epoch": 4.380952380952381,
      "grad_norm": 1.2804452180862427,
      "learning_rate": 0.0001663076923076923,
      "loss": 3.4215,
      "step": 920
    },
    {
      "epoch": 4.404761904761905,
      "grad_norm": 1.2294760942459106,
      "learning_rate": 0.00016553846153846152,
      "loss": 3.4829,
      "step": 925
    },
    {
      "epoch": 4.428571428571429,
      "grad_norm": 1.2602003812789917,
      "learning_rate": 0.00016476923076923073,
      "loss": 3.168,
      "step": 930
    },
    {
      "epoch": 4.4523809523809526,
      "grad_norm": 1.2738908529281616,
      "learning_rate": 0.00016399999999999997,
      "loss": 3.5256,
      "step": 935
    },
    {
      "epoch": 4.476190476190476,
      "grad_norm": 1.4913029670715332,
      "learning_rate": 0.00016323076923076922,
      "loss": 3.2666,
      "step": 940
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.2505203485488892,
      "learning_rate": 0.00016246153846153843,
      "loss": 3.3641,
      "step": 945
    },
    {
      "epoch": 4.523809523809524,
      "grad_norm": 1.300679326057434,
      "learning_rate": 0.00016169230769230768,
      "loss": 3.6505,
      "step": 950
    },
    {
      "epoch": 4.523809523809524,
      "eval_loss": 2.629669189453125,
      "eval_runtime": 0.8606,
      "eval_samples_per_second": 678.605,
      "eval_steps_per_second": 22.078,
      "step": 950
    },
    {
      "epoch": 4.5476190476190474,
      "grad_norm": 1.3081765174865723,
      "learning_rate": 0.00016092307692307692,
      "loss": 3.5681,
      "step": 955
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 1.236903429031372,
      "learning_rate": 0.00016015384615384614,
      "loss": 3.3284,
      "step": 960
    },
    {
      "epoch": 4.595238095238095,
      "grad_norm": 1.2876249551773071,
      "learning_rate": 0.00015938461538461538,
      "loss": 3.3403,
      "step": 965
    },
    {
      "epoch": 4.619047619047619,
      "grad_norm": 1.1348545551300049,
      "learning_rate": 0.00015861538461538462,
      "loss": 3.6793,
      "step": 970
    },
    {
      "epoch": 4.642857142857143,
      "grad_norm": 1.2430750131607056,
      "learning_rate": 0.00015784615384615384,
      "loss": 3.6629,
      "step": 975
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 1.3725098371505737,
      "learning_rate": 0.00015707692307692308,
      "loss": 3.4512,
      "step": 980
    },
    {
      "epoch": 4.690476190476191,
      "grad_norm": 1.3071445226669312,
      "learning_rate": 0.00015630769230769227,
      "loss": 3.6275,
      "step": 985
    },
    {
      "epoch": 4.714285714285714,
      "grad_norm": 1.1935646533966064,
      "learning_rate": 0.00015553846153846152,
      "loss": 3.9229,
      "step": 990
    },
    {
      "epoch": 4.738095238095238,
      "grad_norm": 1.396579623222351,
      "learning_rate": 0.00015476923076923073,
      "loss": 3.6122,
      "step": 995
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 1.3220865726470947,
      "learning_rate": 0.00015399999999999998,
      "loss": 3.5834,
      "step": 1000
    },
    {
      "epoch": 4.761904761904762,
      "eval_loss": 2.6157991886138916,
      "eval_runtime": 0.6785,
      "eval_samples_per_second": 860.675,
      "eval_steps_per_second": 28.001,
      "step": 1000
    },
    {
      "epoch": 4.785714285714286,
      "grad_norm": 1.143519401550293,
      "learning_rate": 0.00015323076923076922,
      "loss": 3.3483,
      "step": 1005
    },
    {
      "epoch": 4.809523809523809,
      "grad_norm": 1.3535236120224,
      "learning_rate": 0.00015246153846153844,
      "loss": 3.452,
      "step": 1010
    },
    {
      "epoch": 4.833333333333333,
      "grad_norm": 1.277222990989685,
      "learning_rate": 0.00015169230769230768,
      "loss": 3.3865,
      "step": 1015
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 1.2530571222305298,
      "learning_rate": 0.00015092307692307692,
      "loss": 3.5795,
      "step": 1020
    },
    {
      "epoch": 4.880952380952381,
      "grad_norm": 1.2850178480148315,
      "learning_rate": 0.00015015384615384614,
      "loss": 3.5031,
      "step": 1025
    },
    {
      "epoch": 4.904761904761905,
      "grad_norm": 1.406679391860962,
      "learning_rate": 0.00014938461538461535,
      "loss": 3.4751,
      "step": 1030
    },
    {
      "epoch": 4.928571428571429,
      "grad_norm": 1.3942627906799316,
      "learning_rate": 0.0001486153846153846,
      "loss": 3.2439,
      "step": 1035
    },
    {
      "epoch": 4.9523809523809526,
      "grad_norm": 1.2737348079681396,
      "learning_rate": 0.00014784615384615384,
      "loss": 3.4787,
      "step": 1040
    },
    {
      "epoch": 4.976190476190476,
      "grad_norm": 1.2730218172073364,
      "learning_rate": 0.00014707692307692306,
      "loss": 3.5884,
      "step": 1045
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.4708242416381836,
      "learning_rate": 0.0001463076923076923,
      "loss": 3.371,
      "step": 1050
    },
    {
      "epoch": 5.0,
      "eval_loss": 2.601346254348755,
      "eval_runtime": 0.5394,
      "eval_samples_per_second": 1082.695,
      "eval_steps_per_second": 35.225,
      "step": 1050
    },
    {
      "epoch": 5.023809523809524,
      "grad_norm": 1.2452952861785889,
      "learning_rate": 0.00014553846153846154,
      "loss": 3.5264,
      "step": 1055
    },
    {
      "epoch": 5.0476190476190474,
      "grad_norm": 1.3204222917556763,
      "learning_rate": 0.00014476923076923076,
      "loss": 3.5148,
      "step": 1060
    },
    {
      "epoch": 5.071428571428571,
      "grad_norm": 1.3532793521881104,
      "learning_rate": 0.00014399999999999998,
      "loss": 3.415,
      "step": 1065
    },
    {
      "epoch": 5.095238095238095,
      "grad_norm": 1.2658418416976929,
      "learning_rate": 0.00014323076923076922,
      "loss": 3.388,
      "step": 1070
    },
    {
      "epoch": 5.119047619047619,
      "grad_norm": 1.3661671876907349,
      "learning_rate": 0.00014246153846153844,
      "loss": 3.3836,
      "step": 1075
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 1.3263428211212158,
      "learning_rate": 0.00014169230769230768,
      "loss": 3.2419,
      "step": 1080
    },
    {
      "epoch": 5.166666666666667,
      "grad_norm": 1.4373493194580078,
      "learning_rate": 0.00014092307692307692,
      "loss": 3.4822,
      "step": 1085
    },
    {
      "epoch": 5.190476190476191,
      "grad_norm": 1.2722132205963135,
      "learning_rate": 0.00014015384615384614,
      "loss": 3.4573,
      "step": 1090
    },
    {
      "epoch": 5.214285714285714,
      "grad_norm": 1.5074907541275024,
      "learning_rate": 0.00013938461538461536,
      "loss": 3.5436,
      "step": 1095
    },
    {
      "epoch": 5.238095238095238,
      "grad_norm": 1.4339628219604492,
      "learning_rate": 0.0001386153846153846,
      "loss": 3.4489,
      "step": 1100
    },
    {
      "epoch": 5.238095238095238,
      "eval_loss": 2.5846240520477295,
      "eval_runtime": 0.7148,
      "eval_samples_per_second": 817.018,
      "eval_steps_per_second": 26.581,
      "step": 1100
    },
    {
      "epoch": 5.261904761904762,
      "grad_norm": 1.275356650352478,
      "learning_rate": 0.00013784615384615384,
      "loss": 3.4154,
      "step": 1105
    },
    {
      "epoch": 5.285714285714286,
      "grad_norm": 1.3123424053192139,
      "learning_rate": 0.00013707692307692306,
      "loss": 3.5031,
      "step": 1110
    },
    {
      "epoch": 5.309523809523809,
      "grad_norm": 1.3746392726898193,
      "learning_rate": 0.0001363076923076923,
      "loss": 3.3313,
      "step": 1115
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 1.3646336793899536,
      "learning_rate": 0.00013553846153846154,
      "loss": 3.6302,
      "step": 1120
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 1.382189154624939,
      "learning_rate": 0.00013476923076923076,
      "loss": 3.451,
      "step": 1125
    },
    {
      "epoch": 5.380952380952381,
      "grad_norm": 1.3240400552749634,
      "learning_rate": 0.00013399999999999998,
      "loss": 3.0832,
      "step": 1130
    },
    {
      "epoch": 5.404761904761905,
      "grad_norm": 1.3406484127044678,
      "learning_rate": 0.00013323076923076922,
      "loss": 3.3354,
      "step": 1135
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 1.4408670663833618,
      "learning_rate": 0.00013246153846153846,
      "loss": 3.3829,
      "step": 1140
    },
    {
      "epoch": 5.4523809523809526,
      "grad_norm": 1.3762167692184448,
      "learning_rate": 0.00013169230769230768,
      "loss": 3.5781,
      "step": 1145
    },
    {
      "epoch": 5.476190476190476,
      "grad_norm": 1.402327537536621,
      "learning_rate": 0.00013092307692307692,
      "loss": 3.3357,
      "step": 1150
    },
    {
      "epoch": 5.476190476190476,
      "eval_loss": 2.5704588890075684,
      "eval_runtime": 0.6057,
      "eval_samples_per_second": 964.098,
      "eval_steps_per_second": 31.366,
      "step": 1150
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.3211551904678345,
      "learning_rate": 0.00013015384615384614,
      "loss": 3.3084,
      "step": 1155
    },
    {
      "epoch": 5.523809523809524,
      "grad_norm": 1.570026159286499,
      "learning_rate": 0.00012938461538461538,
      "loss": 3.3969,
      "step": 1160
    },
    {
      "epoch": 5.5476190476190474,
      "grad_norm": 1.410522222518921,
      "learning_rate": 0.0001286153846153846,
      "loss": 3.3549,
      "step": 1165
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 1.344763994216919,
      "learning_rate": 0.00012784615384615384,
      "loss": 3.3599,
      "step": 1170
    },
    {
      "epoch": 5.595238095238095,
      "grad_norm": 1.3251527547836304,
      "learning_rate": 0.00012707692307692306,
      "loss": 3.2682,
      "step": 1175
    },
    {
      "epoch": 5.619047619047619,
      "grad_norm": 1.4395533800125122,
      "learning_rate": 0.0001263076923076923,
      "loss": 3.5335,
      "step": 1180
    },
    {
      "epoch": 5.642857142857143,
      "grad_norm": 1.447849988937378,
      "learning_rate": 0.00012553846153846152,
      "loss": 3.4698,
      "step": 1185
    },
    {
      "epoch": 5.666666666666667,
      "grad_norm": 1.3775835037231445,
      "learning_rate": 0.00012476923076923076,
      "loss": 3.2757,
      "step": 1190
    },
    {
      "epoch": 5.690476190476191,
      "grad_norm": 1.443588137626648,
      "learning_rate": 0.00012399999999999998,
      "loss": 3.4716,
      "step": 1195
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 1.3880832195281982,
      "learning_rate": 0.00012323076923076922,
      "loss": 3.3237,
      "step": 1200
    },
    {
      "epoch": 5.714285714285714,
      "eval_loss": 2.5580499172210693,
      "eval_runtime": 1.0153,
      "eval_samples_per_second": 575.203,
      "eval_steps_per_second": 18.714,
      "step": 1200
    },
    {
      "epoch": 5.738095238095238,
      "grad_norm": 1.3941996097564697,
      "learning_rate": 0.00012246153846153846,
      "loss": 3.4612,
      "step": 1205
    },
    {
      "epoch": 5.761904761904762,
      "grad_norm": 1.402381181716919,
      "learning_rate": 0.0001216923076923077,
      "loss": 3.4772,
      "step": 1210
    },
    {
      "epoch": 5.785714285714286,
      "grad_norm": 1.3187315464019775,
      "learning_rate": 0.00012092307692307691,
      "loss": 3.261,
      "step": 1215
    },
    {
      "epoch": 5.809523809523809,
      "grad_norm": 1.4121781587600708,
      "learning_rate": 0.00012015384615384614,
      "loss": 3.2503,
      "step": 1220
    },
    {
      "epoch": 5.833333333333333,
      "grad_norm": 1.3330258131027222,
      "learning_rate": 0.00011938461538461537,
      "loss": 3.2242,
      "step": 1225
    },
    {
      "epoch": 5.857142857142857,
      "grad_norm": 1.36571204662323,
      "learning_rate": 0.0001186153846153846,
      "loss": 3.236,
      "step": 1230
    },
    {
      "epoch": 5.880952380952381,
      "grad_norm": 1.3062479496002197,
      "learning_rate": 0.00011784615384615384,
      "loss": 3.2635,
      "step": 1235
    },
    {
      "epoch": 5.904761904761905,
      "grad_norm": 1.3730701208114624,
      "learning_rate": 0.00011707692307692307,
      "loss": 3.2844,
      "step": 1240
    },
    {
      "epoch": 5.928571428571429,
      "grad_norm": 1.2323157787322998,
      "learning_rate": 0.00011630769230769229,
      "loss": 3.4648,
      "step": 1245
    },
    {
      "epoch": 5.9523809523809526,
      "grad_norm": 1.3481816053390503,
      "learning_rate": 0.00011553846153846152,
      "loss": 3.4514,
      "step": 1250
    },
    {
      "epoch": 5.9523809523809526,
      "eval_loss": 2.543971538543701,
      "eval_runtime": 0.7592,
      "eval_samples_per_second": 769.249,
      "eval_steps_per_second": 25.027,
      "step": 1250
    },
    {
      "epoch": 5.976190476190476,
      "grad_norm": 1.3619718551635742,
      "learning_rate": 0.00011476923076923076,
      "loss": 3.3511,
      "step": 1255
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.360896348953247,
      "learning_rate": 0.00011399999999999999,
      "loss": 3.2482,
      "step": 1260
    },
    {
      "epoch": 6.023809523809524,
      "grad_norm": 1.3630988597869873,
      "learning_rate": 0.00011323076923076922,
      "loss": 3.3603,
      "step": 1265
    },
    {
      "epoch": 6.0476190476190474,
      "grad_norm": 1.3125154972076416,
      "learning_rate": 0.00011246153846153845,
      "loss": 3.5274,
      "step": 1270
    },
    {
      "epoch": 6.071428571428571,
      "grad_norm": 1.4120051860809326,
      "learning_rate": 0.00011169230769230768,
      "loss": 3.4329,
      "step": 1275
    },
    {
      "epoch": 6.095238095238095,
      "grad_norm": 1.512793779373169,
      "learning_rate": 0.00011092307692307691,
      "loss": 3.5912,
      "step": 1280
    },
    {
      "epoch": 6.119047619047619,
      "grad_norm": 1.331841230392456,
      "learning_rate": 0.00011015384615384614,
      "loss": 3.2263,
      "step": 1285
    },
    {
      "epoch": 6.142857142857143,
      "grad_norm": 1.3743940591812134,
      "learning_rate": 0.00010938461538461537,
      "loss": 3.3339,
      "step": 1290
    },
    {
      "epoch": 6.166666666666667,
      "grad_norm": 1.4081858396530151,
      "learning_rate": 0.00010861538461538461,
      "loss": 3.3186,
      "step": 1295
    },
    {
      "epoch": 6.190476190476191,
      "grad_norm": 1.3405532836914062,
      "learning_rate": 0.00010784615384615384,
      "loss": 3.1534,
      "step": 1300
    },
    {
      "epoch": 6.190476190476191,
      "eval_loss": 2.5337960720062256,
      "eval_runtime": 0.7189,
      "eval_samples_per_second": 812.388,
      "eval_steps_per_second": 26.43,
      "step": 1300
    },
    {
      "epoch": 6.214285714285714,
      "grad_norm": 1.372404932975769,
      "learning_rate": 0.00010707692307692306,
      "loss": 3.3609,
      "step": 1305
    },
    {
      "epoch": 6.238095238095238,
      "grad_norm": 1.5863932371139526,
      "learning_rate": 0.00010630769230769229,
      "loss": 3.2792,
      "step": 1310
    },
    {
      "epoch": 6.261904761904762,
      "grad_norm": 1.4673242568969727,
      "learning_rate": 0.00010553846153846153,
      "loss": 3.3168,
      "step": 1315
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 1.4490123987197876,
      "learning_rate": 0.00010476923076923076,
      "loss": 3.3545,
      "step": 1320
    },
    {
      "epoch": 6.309523809523809,
      "grad_norm": 1.3621340990066528,
      "learning_rate": 0.000104,
      "loss": 3.4736,
      "step": 1325
    },
    {
      "epoch": 6.333333333333333,
      "grad_norm": 1.389786958694458,
      "learning_rate": 0.00010323076923076922,
      "loss": 3.4024,
      "step": 1330
    },
    {
      "epoch": 6.357142857142857,
      "grad_norm": 1.2904565334320068,
      "learning_rate": 0.00010246153846153844,
      "loss": 3.0845,
      "step": 1335
    },
    {
      "epoch": 6.380952380952381,
      "grad_norm": 1.4771106243133545,
      "learning_rate": 0.00010169230769230768,
      "loss": 3.2531,
      "step": 1340
    },
    {
      "epoch": 6.404761904761905,
      "grad_norm": 1.5810190439224243,
      "learning_rate": 0.00010092307692307691,
      "loss": 3.2741,
      "step": 1345
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 1.3718397617340088,
      "learning_rate": 0.00010015384615384614,
      "loss": 3.436,
      "step": 1350
    },
    {
      "epoch": 6.428571428571429,
      "eval_loss": 2.5243399143218994,
      "eval_runtime": 0.7502,
      "eval_samples_per_second": 778.447,
      "eval_steps_per_second": 25.326,
      "step": 1350
    },
    {
      "epoch": 6.4523809523809526,
      "grad_norm": 1.4326359033584595,
      "learning_rate": 9.938461538461539e-05,
      "loss": 3.153,
      "step": 1355
    },
    {
      "epoch": 6.476190476190476,
      "grad_norm": 1.4735389947891235,
      "learning_rate": 9.861538461538462e-05,
      "loss": 3.4352,
      "step": 1360
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.4734489917755127,
      "learning_rate": 9.784615384615383e-05,
      "loss": 3.3692,
      "step": 1365
    },
    {
      "epoch": 6.523809523809524,
      "grad_norm": 1.434278130531311,
      "learning_rate": 9.707692307692306e-05,
      "loss": 3.3416,
      "step": 1370
    },
    {
      "epoch": 6.5476190476190474,
      "grad_norm": 1.4910632371902466,
      "learning_rate": 9.630769230769229e-05,
      "loss": 3.4099,
      "step": 1375
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 1.332633137702942,
      "learning_rate": 9.553846153846153e-05,
      "loss": 3.0805,
      "step": 1380
    },
    {
      "epoch": 6.595238095238095,
      "grad_norm": 1.5305542945861816,
      "learning_rate": 9.476923076923076e-05,
      "loss": 3.3479,
      "step": 1385
    },
    {
      "epoch": 6.619047619047619,
      "grad_norm": 1.5302287340164185,
      "learning_rate": 9.4e-05,
      "loss": 3.2752,
      "step": 1390
    },
    {
      "epoch": 6.642857142857143,
      "grad_norm": 1.4744532108306885,
      "learning_rate": 9.323076923076921e-05,
      "loss": 3.3638,
      "step": 1395
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 1.4507662057876587,
      "learning_rate": 9.246153846153845e-05,
      "loss": 3.1882,
      "step": 1400
    },
    {
      "epoch": 6.666666666666667,
      "eval_loss": 2.511672019958496,
      "eval_runtime": 0.5369,
      "eval_samples_per_second": 1087.808,
      "eval_steps_per_second": 35.391,
      "step": 1400
    },
    {
      "epoch": 6.690476190476191,
      "grad_norm": 1.317215085029602,
      "learning_rate": 9.169230769230768e-05,
      "loss": 3.2879,
      "step": 1405
    },
    {
      "epoch": 6.714285714285714,
      "grad_norm": 1.4677282571792603,
      "learning_rate": 9.092307692307691e-05,
      "loss": 3.5436,
      "step": 1410
    },
    {
      "epoch": 6.738095238095238,
      "grad_norm": 1.4839626550674438,
      "learning_rate": 9.015384615384614e-05,
      "loss": 3.4233,
      "step": 1415
    },
    {
      "epoch": 6.761904761904762,
      "grad_norm": 1.4354244470596313,
      "learning_rate": 8.938461538461539e-05,
      "loss": 3.3952,
      "step": 1420
    },
    {
      "epoch": 6.785714285714286,
      "grad_norm": 1.5452994108200073,
      "learning_rate": 8.861538461538462e-05,
      "loss": 3.5306,
      "step": 1425
    },
    {
      "epoch": 6.809523809523809,
      "grad_norm": 1.4553642272949219,
      "learning_rate": 8.784615384615383e-05,
      "loss": 3.2573,
      "step": 1430
    },
    {
      "epoch": 6.833333333333333,
      "grad_norm": 1.4190318584442139,
      "learning_rate": 8.707692307692306e-05,
      "loss": 3.3793,
      "step": 1435
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 1.4350619316101074,
      "learning_rate": 8.63076923076923e-05,
      "loss": 3.3455,
      "step": 1440
    },
    {
      "epoch": 6.880952380952381,
      "grad_norm": 1.550173282623291,
      "learning_rate": 8.553846153846154e-05,
      "loss": 3.3942,
      "step": 1445
    },
    {
      "epoch": 6.904761904761905,
      "grad_norm": 1.415472149848938,
      "learning_rate": 8.476923076923077e-05,
      "loss": 3.3825,
      "step": 1450
    },
    {
      "epoch": 6.904761904761905,
      "eval_loss": 2.5015552043914795,
      "eval_runtime": 0.4154,
      "eval_samples_per_second": 1405.831,
      "eval_steps_per_second": 45.738,
      "step": 1450
    },
    {
      "epoch": 6.928571428571429,
      "grad_norm": 1.436565637588501,
      "learning_rate": 8.4e-05,
      "loss": 3.4765,
      "step": 1455
    },
    {
      "epoch": 6.9523809523809526,
      "grad_norm": 1.4700630903244019,
      "learning_rate": 8.323076923076921e-05,
      "loss": 3.0081,
      "step": 1460
    },
    {
      "epoch": 6.976190476190476,
      "grad_norm": 1.4764806032180786,
      "learning_rate": 8.246153846153845e-05,
      "loss": 3.267,
      "step": 1465
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.077099084854126,
      "learning_rate": 8.169230769230768e-05,
      "loss": 3.2336,
      "step": 1470
    },
    {
      "epoch": 7.023809523809524,
      "grad_norm": 1.411603569984436,
      "learning_rate": 8.092307692307691e-05,
      "loss": 3.2632,
      "step": 1475
    },
    {
      "epoch": 7.0476190476190474,
      "grad_norm": 1.405824065208435,
      "learning_rate": 8.015384615384616e-05,
      "loss": 3.3226,
      "step": 1480
    },
    {
      "epoch": 7.071428571428571,
      "grad_norm": 1.5065678358078003,
      "learning_rate": 7.938461538461539e-05,
      "loss": 3.4747,
      "step": 1485
    },
    {
      "epoch": 7.095238095238095,
      "grad_norm": 1.4690946340560913,
      "learning_rate": 7.86153846153846e-05,
      "loss": 3.2757,
      "step": 1490
    },
    {
      "epoch": 7.119047619047619,
      "grad_norm": 1.4535750150680542,
      "learning_rate": 7.784615384615383e-05,
      "loss": 3.1556,
      "step": 1495
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 1.346412181854248,
      "learning_rate": 7.707692307692306e-05,
      "loss": 3.3405,
      "step": 1500
    },
    {
      "epoch": 7.142857142857143,
      "eval_loss": 2.4973371028900146,
      "eval_runtime": 0.3876,
      "eval_samples_per_second": 1506.523,
      "eval_steps_per_second": 49.014,
      "step": 1500
    },
    {
      "epoch": 7.166666666666667,
      "grad_norm": 1.465560793876648,
      "learning_rate": 7.630769230769231e-05,
      "loss": 3.2076,
      "step": 1505
    },
    {
      "epoch": 7.190476190476191,
      "grad_norm": 1.5065909624099731,
      "learning_rate": 7.553846153846154e-05,
      "loss": 3.4149,
      "step": 1510
    },
    {
      "epoch": 7.214285714285714,
      "grad_norm": 1.48324716091156,
      "learning_rate": 7.476923076923077e-05,
      "loss": 3.0526,
      "step": 1515
    },
    {
      "epoch": 7.238095238095238,
      "grad_norm": 1.50421941280365,
      "learning_rate": 7.4e-05,
      "loss": 3.309,
      "step": 1520
    },
    {
      "epoch": 7.261904761904762,
      "grad_norm": 1.4191539287567139,
      "learning_rate": 7.323076923076923e-05,
      "loss": 3.0682,
      "step": 1525
    },
    {
      "epoch": 7.285714285714286,
      "grad_norm": 1.3925849199295044,
      "learning_rate": 7.246153846153846e-05,
      "loss": 3.1412,
      "step": 1530
    },
    {
      "epoch": 7.309523809523809,
      "grad_norm": 1.5205128192901611,
      "learning_rate": 7.169230769230769e-05,
      "loss": 3.1871,
      "step": 1535
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 1.486456274986267,
      "learning_rate": 7.092307692307692e-05,
      "loss": 3.6746,
      "step": 1540
    },
    {
      "epoch": 7.357142857142857,
      "grad_norm": 1.4124587774276733,
      "learning_rate": 7.015384615384615e-05,
      "loss": 3.182,
      "step": 1545
    },
    {
      "epoch": 7.380952380952381,
      "grad_norm": 1.5332841873168945,
      "learning_rate": 6.938461538461537e-05,
      "loss": 3.4879,
      "step": 1550
    },
    {
      "epoch": 7.380952380952381,
      "eval_loss": 2.4899423122406006,
      "eval_runtime": 0.8818,
      "eval_samples_per_second": 662.282,
      "eval_steps_per_second": 21.547,
      "step": 1550
    },
    {
      "epoch": 7.404761904761905,
      "grad_norm": 1.4834144115447998,
      "learning_rate": 6.86153846153846e-05,
      "loss": 3.5531,
      "step": 1555
    },
    {
      "epoch": 7.428571428571429,
      "grad_norm": 1.4667819738388062,
      "learning_rate": 6.784615384615383e-05,
      "loss": 3.2631,
      "step": 1560
    },
    {
      "epoch": 7.4523809523809526,
      "grad_norm": 1.4422425031661987,
      "learning_rate": 6.707692307692308e-05,
      "loss": 3.1266,
      "step": 1565
    },
    {
      "epoch": 7.476190476190476,
      "grad_norm": 1.5754181146621704,
      "learning_rate": 6.63076923076923e-05,
      "loss": 3.0877,
      "step": 1570
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.4355549812316895,
      "learning_rate": 6.553846153846154e-05,
      "loss": 3.2982,
      "step": 1575
    },
    {
      "epoch": 7.523809523809524,
      "grad_norm": 1.4892053604125977,
      "learning_rate": 6.476923076923077e-05,
      "loss": 3.3548,
      "step": 1580
    },
    {
      "epoch": 7.5476190476190474,
      "grad_norm": 1.4048422574996948,
      "learning_rate": 6.4e-05,
      "loss": 3.3018,
      "step": 1585
    },
    {
      "epoch": 7.571428571428571,
      "grad_norm": 1.47536301612854,
      "learning_rate": 6.323076923076923e-05,
      "loss": 3.3286,
      "step": 1590
    },
    {
      "epoch": 7.595238095238095,
      "grad_norm": 1.4111297130584717,
      "learning_rate": 6.246153846153846e-05,
      "loss": 3.3234,
      "step": 1595
    },
    {
      "epoch": 7.619047619047619,
      "grad_norm": 1.495204210281372,
      "learning_rate": 6.169230769230769e-05,
      "loss": 3.2701,
      "step": 1600
    },
    {
      "epoch": 7.619047619047619,
      "eval_loss": 2.483781337738037,
      "eval_runtime": 0.4777,
      "eval_samples_per_second": 1222.594,
      "eval_steps_per_second": 39.776,
      "step": 1600
    },
    {
      "epoch": 7.642857142857143,
      "grad_norm": 1.3989365100860596,
      "learning_rate": 6.0923076923076916e-05,
      "loss": 3.1746,
      "step": 1605
    },
    {
      "epoch": 7.666666666666667,
      "grad_norm": 1.4500844478607178,
      "learning_rate": 6.015384615384615e-05,
      "loss": 3.3539,
      "step": 1610
    },
    {
      "epoch": 7.690476190476191,
      "grad_norm": 1.482526421546936,
      "learning_rate": 5.938461538461538e-05,
      "loss": 3.2897,
      "step": 1615
    },
    {
      "epoch": 7.714285714285714,
      "grad_norm": 1.4370944499969482,
      "learning_rate": 5.8615384615384606e-05,
      "loss": 3.4359,
      "step": 1620
    },
    {
      "epoch": 7.738095238095238,
      "grad_norm": 1.5583173036575317,
      "learning_rate": 5.784615384615384e-05,
      "loss": 3.4216,
      "step": 1625
    },
    {
      "epoch": 7.761904761904762,
      "grad_norm": 1.4612246751785278,
      "learning_rate": 5.707692307692308e-05,
      "loss": 3.1554,
      "step": 1630
    },
    {
      "epoch": 7.785714285714286,
      "grad_norm": 1.447586178779602,
      "learning_rate": 5.63076923076923e-05,
      "loss": 3.2481,
      "step": 1635
    },
    {
      "epoch": 7.809523809523809,
      "grad_norm": 1.439264178276062,
      "learning_rate": 5.553846153846153e-05,
      "loss": 3.2957,
      "step": 1640
    },
    {
      "epoch": 7.833333333333333,
      "grad_norm": 1.461876630783081,
      "learning_rate": 5.476923076923077e-05,
      "loss": 3.3332,
      "step": 1645
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 1.3780949115753174,
      "learning_rate": 5.399999999999999e-05,
      "loss": 3.1696,
      "step": 1650
    },
    {
      "epoch": 7.857142857142857,
      "eval_loss": 2.475738286972046,
      "eval_runtime": 2.5196,
      "eval_samples_per_second": 231.779,
      "eval_steps_per_second": 7.541,
      "step": 1650
    },
    {
      "epoch": 7.880952380952381,
      "grad_norm": 1.450547218322754,
      "learning_rate": 5.323076923076923e-05,
      "loss": 3.2105,
      "step": 1655
    },
    {
      "epoch": 7.904761904761905,
      "grad_norm": 1.4924391508102417,
      "learning_rate": 5.246153846153846e-05,
      "loss": 3.0833,
      "step": 1660
    },
    {
      "epoch": 7.928571428571429,
      "grad_norm": 1.4085612297058105,
      "learning_rate": 5.169230769230769e-05,
      "loss": 3.5428,
      "step": 1665
    },
    {
      "epoch": 7.9523809523809526,
      "grad_norm": 1.5344544649124146,
      "learning_rate": 5.092307692307692e-05,
      "loss": 3.4739,
      "step": 1670
    },
    {
      "epoch": 7.976190476190476,
      "grad_norm": 1.5131012201309204,
      "learning_rate": 5.0153846153846154e-05,
      "loss": 3.317,
      "step": 1675
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.6311564445495605,
      "learning_rate": 4.938461538461538e-05,
      "loss": 3.1777,
      "step": 1680
    },
    {
      "epoch": 8.023809523809524,
      "grad_norm": 1.53813898563385,
      "learning_rate": 4.861538461538461e-05,
      "loss": 3.3674,
      "step": 1685
    },
    {
      "epoch": 8.047619047619047,
      "grad_norm": 1.497086524963379,
      "learning_rate": 4.784615384615384e-05,
      "loss": 3.1005,
      "step": 1690
    },
    {
      "epoch": 8.071428571428571,
      "grad_norm": 1.5096731185913086,
      "learning_rate": 4.707692307692307e-05,
      "loss": 3.2046,
      "step": 1695
    },
    {
      "epoch": 8.095238095238095,
      "grad_norm": 1.4881325960159302,
      "learning_rate": 4.63076923076923e-05,
      "loss": 3.2468,
      "step": 1700
    },
    {
      "epoch": 8.095238095238095,
      "eval_loss": 2.473647117614746,
      "eval_runtime": 0.7872,
      "eval_samples_per_second": 741.887,
      "eval_steps_per_second": 24.137,
      "step": 1700
    },
    {
      "epoch": 8.119047619047619,
      "grad_norm": 1.5120714902877808,
      "learning_rate": 4.553846153846154e-05,
      "loss": 3.297,
      "step": 1705
    },
    {
      "epoch": 8.142857142857142,
      "grad_norm": 1.460508942604065,
      "learning_rate": 4.476923076923076e-05,
      "loss": 3.2645,
      "step": 1710
    },
    {
      "epoch": 8.166666666666666,
      "grad_norm": 1.3821245431900024,
      "learning_rate": 4.4e-05,
      "loss": 3.1916,
      "step": 1715
    },
    {
      "epoch": 8.19047619047619,
      "grad_norm": 1.533334732055664,
      "learning_rate": 4.323076923076923e-05,
      "loss": 3.357,
      "step": 1720
    },
    {
      "epoch": 8.214285714285714,
      "grad_norm": 1.4461830854415894,
      "learning_rate": 4.246153846153846e-05,
      "loss": 3.0881,
      "step": 1725
    },
    {
      "epoch": 8.238095238095237,
      "grad_norm": 1.5297399759292603,
      "learning_rate": 4.169230769230769e-05,
      "loss": 3.4183,
      "step": 1730
    },
    {
      "epoch": 8.261904761904763,
      "grad_norm": 1.6001040935516357,
      "learning_rate": 4.0923076923076925e-05,
      "loss": 3.0582,
      "step": 1735
    },
    {
      "epoch": 8.285714285714286,
      "grad_norm": 1.4208433628082275,
      "learning_rate": 4.015384615384615e-05,
      "loss": 3.2327,
      "step": 1740
    },
    {
      "epoch": 8.30952380952381,
      "grad_norm": 1.4665098190307617,
      "learning_rate": 3.9384615384615384e-05,
      "loss": 3.1982,
      "step": 1745
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 1.5241131782531738,
      "learning_rate": 3.8615384615384614e-05,
      "loss": 3.2298,
      "step": 1750
    },
    {
      "epoch": 8.333333333333334,
      "eval_loss": 2.465487241744995,
      "eval_runtime": 1.4863,
      "eval_samples_per_second": 392.917,
      "eval_steps_per_second": 12.783,
      "step": 1750
    },
    {
      "epoch": 8.357142857142858,
      "grad_norm": 1.5263453722000122,
      "learning_rate": 3.784615384615384e-05,
      "loss": 3.3504,
      "step": 1755
    },
    {
      "epoch": 8.380952380952381,
      "grad_norm": 1.6164878606796265,
      "learning_rate": 3.7076923076923074e-05,
      "loss": 3.3126,
      "step": 1760
    },
    {
      "epoch": 8.404761904761905,
      "grad_norm": 1.5645737648010254,
      "learning_rate": 3.6307692307692304e-05,
      "loss": 3.1825,
      "step": 1765
    },
    {
      "epoch": 8.428571428571429,
      "grad_norm": 1.4840127229690552,
      "learning_rate": 3.553846153846153e-05,
      "loss": 3.1342,
      "step": 1770
    },
    {
      "epoch": 8.452380952380953,
      "grad_norm": 1.5766336917877197,
      "learning_rate": 3.476923076923076e-05,
      "loss": 3.0431,
      "step": 1775
    },
    {
      "epoch": 8.476190476190476,
      "grad_norm": 1.722880482673645,
      "learning_rate": 3.399999999999999e-05,
      "loss": 3.5541,
      "step": 1780
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.5449455976486206,
      "learning_rate": 3.323076923076923e-05,
      "loss": 3.2004,
      "step": 1785
    },
    {
      "epoch": 8.523809523809524,
      "grad_norm": 1.70308256149292,
      "learning_rate": 3.246153846153846e-05,
      "loss": 3.5763,
      "step": 1790
    },
    {
      "epoch": 8.547619047619047,
      "grad_norm": 1.5595648288726807,
      "learning_rate": 3.169230769230769e-05,
      "loss": 3.2475,
      "step": 1795
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 1.5605648756027222,
      "learning_rate": 3.092307692307692e-05,
      "loss": 3.5897,
      "step": 1800
    },
    {
      "epoch": 8.571428571428571,
      "eval_loss": 2.4620420932769775,
      "eval_runtime": 1.0145,
      "eval_samples_per_second": 575.626,
      "eval_steps_per_second": 18.728,
      "step": 1800
    },
    {
      "epoch": 8.595238095238095,
      "grad_norm": 1.4398431777954102,
      "learning_rate": 3.0153846153846152e-05,
      "loss": 3.2506,
      "step": 1805
    },
    {
      "epoch": 8.619047619047619,
      "grad_norm": 1.3979657888412476,
      "learning_rate": 2.938461538461538e-05,
      "loss": 3.3802,
      "step": 1810
    },
    {
      "epoch": 8.642857142857142,
      "grad_norm": 1.4765124320983887,
      "learning_rate": 2.8615384615384615e-05,
      "loss": 3.1025,
      "step": 1815
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 1.4082608222961426,
      "learning_rate": 2.784615384615384e-05,
      "loss": 3.1233,
      "step": 1820
    },
    {
      "epoch": 8.69047619047619,
      "grad_norm": 1.5704275369644165,
      "learning_rate": 2.7076923076923078e-05,
      "loss": 3.1962,
      "step": 1825
    },
    {
      "epoch": 8.714285714285714,
      "grad_norm": 1.5768768787384033,
      "learning_rate": 2.6307692307692304e-05,
      "loss": 3.4728,
      "step": 1830
    },
    {
      "epoch": 8.738095238095237,
      "grad_norm": 1.5292679071426392,
      "learning_rate": 2.5538461538461534e-05,
      "loss": 3.1233,
      "step": 1835
    },
    {
      "epoch": 8.761904761904763,
      "grad_norm": 1.5168704986572266,
      "learning_rate": 2.4769230769230767e-05,
      "loss": 3.4592,
      "step": 1840
    },
    {
      "epoch": 8.785714285714286,
      "grad_norm": 1.4789878129959106,
      "learning_rate": 2.3999999999999997e-05,
      "loss": 3.3444,
      "step": 1845
    },
    {
      "epoch": 8.80952380952381,
      "grad_norm": 1.4040504693984985,
      "learning_rate": 2.3230769230769227e-05,
      "loss": 3.2228,
      "step": 1850
    },
    {
      "epoch": 8.80952380952381,
      "eval_loss": 2.458143711090088,
      "eval_runtime": 0.5975,
      "eval_samples_per_second": 977.337,
      "eval_steps_per_second": 31.797,
      "step": 1850
    },
    {
      "epoch": 8.833333333333334,
      "grad_norm": 1.4396730661392212,
      "learning_rate": 2.246153846153846e-05,
      "loss": 3.0978,
      "step": 1855
    },
    {
      "epoch": 8.857142857142858,
      "grad_norm": 1.492035150527954,
      "learning_rate": 2.169230769230769e-05,
      "loss": 3.1457,
      "step": 1860
    },
    {
      "epoch": 8.880952380952381,
      "grad_norm": 1.7222278118133545,
      "learning_rate": 2.092307692307692e-05,
      "loss": 3.5224,
      "step": 1865
    },
    {
      "epoch": 8.904761904761905,
      "grad_norm": 1.5582516193389893,
      "learning_rate": 2.0153846153846153e-05,
      "loss": 3.178,
      "step": 1870
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 1.6103489398956299,
      "learning_rate": 1.9384615384615383e-05,
      "loss": 3.2304,
      "step": 1875
    },
    {
      "epoch": 8.952380952380953,
      "grad_norm": 1.5142916440963745,
      "learning_rate": 1.8615384615384616e-05,
      "loss": 3.2687,
      "step": 1880
    },
    {
      "epoch": 8.976190476190476,
      "grad_norm": 1.3783739805221558,
      "learning_rate": 1.7846153846153846e-05,
      "loss": 3.1636,
      "step": 1885
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.610726833343506,
      "learning_rate": 1.7076923076923076e-05,
      "loss": 3.2398,
      "step": 1890
    },
    {
      "epoch": 9.023809523809524,
      "grad_norm": 1.5210120677947998,
      "learning_rate": 1.630769230769231e-05,
      "loss": 3.0068,
      "step": 1895
    },
    {
      "epoch": 9.047619047619047,
      "grad_norm": 1.6332030296325684,
      "learning_rate": 1.5538461538461535e-05,
      "loss": 3.2972,
      "step": 1900
    },
    {
      "epoch": 9.047619047619047,
      "eval_loss": 2.455306053161621,
      "eval_runtime": 0.7617,
      "eval_samples_per_second": 766.683,
      "eval_steps_per_second": 24.943,
      "step": 1900
    },
    {
      "epoch": 9.071428571428571,
      "grad_norm": 1.4425749778747559,
      "learning_rate": 1.4769230769230768e-05,
      "loss": 3.2778,
      "step": 1905
    },
    {
      "epoch": 9.095238095238095,
      "grad_norm": 1.62883722782135,
      "learning_rate": 1.4e-05,
      "loss": 3.3659,
      "step": 1910
    },
    {
      "epoch": 9.119047619047619,
      "grad_norm": 1.4393328428268433,
      "learning_rate": 1.323076923076923e-05,
      "loss": 3.3588,
      "step": 1915
    },
    {
      "epoch": 9.142857142857142,
      "grad_norm": 1.5719258785247803,
      "learning_rate": 1.2461538461538461e-05,
      "loss": 3.2801,
      "step": 1920
    },
    {
      "epoch": 9.166666666666666,
      "grad_norm": 1.517726182937622,
      "learning_rate": 1.1692307692307693e-05,
      "loss": 3.355,
      "step": 1925
    },
    {
      "epoch": 9.19047619047619,
      "grad_norm": 1.5046460628509521,
      "learning_rate": 1.092307692307692e-05,
      "loss": 3.2217,
      "step": 1930
    },
    {
      "epoch": 9.214285714285714,
      "grad_norm": 1.406567096710205,
      "learning_rate": 1.0153846153846152e-05,
      "loss": 3.3222,
      "step": 1935
    },
    {
      "epoch": 9.238095238095237,
      "grad_norm": 1.5871834754943848,
      "learning_rate": 9.384615384615384e-06,
      "loss": 2.9714,
      "step": 1940
    },
    {
      "epoch": 9.261904761904763,
      "grad_norm": 1.5151845216751099,
      "learning_rate": 8.615384615384615e-06,
      "loss": 2.9582,
      "step": 1945
    },
    {
      "epoch": 9.285714285714286,
      "grad_norm": 1.5776878595352173,
      "learning_rate": 7.846153846153845e-06,
      "loss": 3.3096,
      "step": 1950
    },
    {
      "epoch": 9.285714285714286,
      "eval_loss": 2.4546959400177,
      "eval_runtime": 1.0238,
      "eval_samples_per_second": 570.398,
      "eval_steps_per_second": 18.557,
      "step": 1950
    },
    {
      "epoch": 9.30952380952381,
      "grad_norm": 1.608994483947754,
      "learning_rate": 7.076923076923076e-06,
      "loss": 3.0976,
      "step": 1955
    },
    {
      "epoch": 9.333333333333334,
      "grad_norm": 1.5494215488433838,
      "learning_rate": 6.307692307692307e-06,
      "loss": 3.2479,
      "step": 1960
    },
    {
      "epoch": 9.357142857142858,
      "grad_norm": 1.535919427871704,
      "learning_rate": 5.5384615384615385e-06,
      "loss": 3.1978,
      "step": 1965
    },
    {
      "epoch": 9.380952380952381,
      "grad_norm": 1.4841469526290894,
      "learning_rate": 4.769230769230769e-06,
      "loss": 3.041,
      "step": 1970
    },
    {
      "epoch": 9.404761904761905,
      "grad_norm": 1.546647071838379,
      "learning_rate": 4e-06,
      "loss": 3.28,
      "step": 1975
    },
    {
      "epoch": 9.428571428571429,
      "grad_norm": 1.493125319480896,
      "learning_rate": 3.2307692307692305e-06,
      "loss": 3.2044,
      "step": 1980
    },
    {
      "epoch": 9.452380952380953,
      "grad_norm": 1.5976476669311523,
      "learning_rate": 2.4615384615384615e-06,
      "loss": 3.3153,
      "step": 1985
    },
    {
      "epoch": 9.476190476190476,
      "grad_norm": 1.6146982908248901,
      "learning_rate": 1.6923076923076924e-06,
      "loss": 3.2999,
      "step": 1990
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.532423734664917,
      "learning_rate": 9.23076923076923e-07,
      "loss": 3.0169,
      "step": 1995
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 1.4736993312835693,
      "learning_rate": 1.5384615384615385e-07,
      "loss": 3.4016,
      "step": 2000
    },
    {
      "epoch": 9.523809523809524,
      "eval_loss": 2.4542529582977295,
      "eval_runtime": 0.8647,
      "eval_samples_per_second": 675.364,
      "eval_steps_per_second": 21.972,
      "step": 2000
    }
  ],
  "logging_steps": 5,
  "max_steps": 2000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9718451306496.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
